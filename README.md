# ðŸŸï¸âš½ Football Scraper

## ðŸš€ Introduction

This is a simple yet modular Python-based **data pipeline** designed to scrape **football data** from the web. The goal is to gather various football metrics for the **top 5 European leagues**, including:

- âœ… League Standings  
- âŒ Top Goal Scorers  
- âŒ Top Assists  
- âŒ Top Passers  
- âŒ Most Shots on Target  

The current version scrapes data from [twtd.co.uk](https://www.twtd.co.uk) for a specified **match date**, transforms it, and stores the result in a local **CSV file**.

---

## ðŸ› ï¸ Dependencies

The script uses the following Python modules:

- `os` â€“ for path and file operations  
- `datetime` â€“ to handle date formatting  
- `pandas` â€“ for dataframe creation and manipulation  
- `dotenv` â€“ to manage environment variables  
- `selenium` â€“ to automate web scraping  
- `logging` â€“ for runtime logs and error tracking  

Install all dependencies using:

```bash
pip install -r requirements.txt
```

---

## ðŸ§± Code Blocks

The script is divided into modular components for clarity and reusability:

### ðŸ“ Logger

Creates a **logging system** to track messages, warnings, and errors. All logs are written to a file within a dedicated `log/` directory.

### âš™ï¸ Config

Loads and initializes **environment variables** (via `.env`) that are needed to access, store, or process data.

### ðŸŒ Webpage Loader

Uses **Selenium Chrome WebDriver** to open the webpage dynamically based on a match date provided.

### ðŸªŸ Popup Handler

Closes any **unexpected pop-ups** or cookie banners using predefined XPath logic.

### ðŸ§ª Data Extractor

Extracts football-related stats using **XPath selectors**. The data is parsed from HTML and stored as a list of lists.

### ðŸ”„ Data Transformer

Converts the raw list data into a **Pandas DataFrame**, cleaning and reshaping as needed. Adds a `match_date` column to enrich the dataset.

### ðŸ’¾ Data Loader

Saves the final dataset to a **CSV file** locally (additional formats like JSON or Parquet planned for future versions).

---

## ðŸ“š Lessons Learnt / Future Developments

Every good software project has a roadmap for improvement. Here are a few enhancements planned for this scraper:

- ðŸ”¥ **Exception Handling** â€“ Improve the error-handling pipeline and make logging more robust.
- ðŸ§¾ **Additional File Formats** â€“ Add support for saving data in JSON, Parquet, and text formats.
- ðŸ“Š **More Data Points** â€“ Scrape additional stats like assists, yellow/red cards, and player performance.
- ðŸ§  **Type Hints** â€“ Apply consistent Python type hints across the codebase to improve code readability and IDE support.
- â° **Scheduling / Orchestration** â€“ Automate scraper execution weekly using schedulers like cron, Airflow, or Prefect.
- ðŸ§ª **Unit Testing** â€“ Add test coverage using `unittest` or `pytest` for key modules and functions.

---

## ðŸ Conclusion

This project showcases how to architect a **modular and scalable scraping pipeline** using Python, Selenium, and Pandas. It emphasizes reusability and separation of concerns, and is built with growth in mind.

If extended further, the pipeline has the potential to evolve into a **production-grade data service** for football statistics.

> ðŸ’¡ By adhering to SOLID principles and clean coding patterns, this scraper can evolve in any direction â€” with minimal refactoring effort.

---
